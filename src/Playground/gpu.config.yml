analyzer:
  device: cuda
  optimize_transforms: true
  reader:
    _target_: facetorch.analyzer.reader.ImageReader
    device:
      _target_: torch.device
      type: ${analyzer.device}
    optimize_transform: ${analyzer.optimize_transforms}
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
      - _target_: facetorch.transforms.SquarePad
      - _target_: torchvision.transforms.Resize        
        size:
        - 1080
        antialias: True
  detector:
    _target_: facetorch.analyzer.detector.FaceDetector
    downloader:
      _target_: facetorch.downloader.DownloaderGDrive
      file_id: 1eMuOdGkiNCOUTiEbKKoPCHGCuDgiKeNC
      path_local: /home/qihan/catkin_ws/src/multicam/model/facetorch/models/torchscript/detector/1/model.pt
    device:
      _target_: torch.device
      type: ${analyzer.device}
    reverse_colors: true
    preprocessor:
      _target_: facetorch.analyzer.detector.pre.DetectorPreProcessor
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
        - _target_: torchvision.transforms.Normalize
          mean:
          - 104.0
          - 117.0
          - 123.0
          std:
          - 1.0
          - 1.0
          - 1.0
      device:
        _target_: torch.device
        type: ${analyzer.device}
      optimize_transform: ${analyzer.optimize_transforms}
      reverse_colors: ${analyzer.detector.reverse_colors}
    postprocessor:
      _target_: facetorch.analyzer.detector.post.PostRetFace
      transform: None
      device:
        _target_: torch.device
        type: ${analyzer.device}
      optimize_transform: ${analyzer.optimize_transforms}
      confidence_threshold: 0.02
      top_k: 5000
      nms_threshold: 0.4
      keep_top_k: 750
      score_threshold: 0.6
      prior_box:
        _target_: facetorch.analyzer.detector.post.PriorBox
        min_sizes:
        - - 16
          - 32
        - - 64
          - 128
        - - 256
          - 512
        steps:
        - 8
        - 16
        - 32
        clip: false
      variance:
      - 0.1
      - 0.2
      reverse_colors: ${analyzer.detector.reverse_colors}
      expand_box_ratio: 0.0
  unifier:
    _target_: facetorch.analyzer.unifier.FaceUnifier
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
      - _target_: torchvision.transforms.Normalize
        mean:
        - -123.0
        - -117.0
        - -104.0
        std:
        - 255.0
        - 255.0
        - 255.0
      - _target_: torchvision.transforms.Resize        
        size:
        - 380
        - 380
        antialias: True
    device:
      _target_: torch.device
      type: ${analyzer.device}
    optimize_transform: ${analyzer.optimize_transforms}
  predictor:
    embed:
      _target_: facetorch.analyzer.predictor.FacePredictor
      downloader:
        _target_: facetorch.downloader.DownloaderGDrive
        file_id: 19h3kqar1wlELAmM5hDyj9tlrUh8yjrCl
        path_local: /home/qihan/catkin_ws/src/multicam/model/facetorch/models/torchscript/predictor/embed/1/model.pt
      device:
        _target_: torch.device
        type: ${analyzer.device}
      preprocessor:
        _target_: facetorch.analyzer.predictor.pre.PredictorPreProcessor
        transform:
          _target_: torchvision.transforms.Compose
          transforms:
          - _target_: torchvision.transforms.Resize            
            size:
            - 244
            - 244
            antialias: True
          - _target_: torchvision.transforms.Normalize
            mean:
            - 0.485
            - 0.456
            - 0.406
            std:
            - 0.228
            - 0.224
            - 0.225
        device:
          _target_: torch.device
          type: ${analyzer.predictor.embed.device.type}
        optimize_transform: ${analyzer.optimize_transforms}
        reverse_colors: false
      postprocessor:
        _target_: facetorch.analyzer.predictor.post.PostEmbedder
        transform: None
        device:
          _target_: torch.device
          type: ${analyzer.predictor.embed.device.type}
        optimize_transform: ${analyzer.optimize_transforms}
        labels:
        - abstract
    
  
  logger:
    _target_: facetorch.logger.LoggerJsonFile
    name: facetorch
    level: OFF
    path_file: /home/qihan/catkin_ws/src/multicam/model/facetorch/logs/facetorch/main.log
    json_format: '%(asctime)s %(levelname)s %(message)s'
main:
  sleep: 3
debug: true
batch_size: 32
fix_img_size: true
return_img_data: true
include_tensors: true
