{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from face_crop_plus import Cropper\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "directory = '/home/qihan/Playground/lighting_test'\n",
    "\n",
    "from facetorch import FaceAnalyzer\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Dict\n",
    "import operator\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import operator\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "cropper = Cropper(face_factor=0.7, strategy=\"largest\",device=\"cuda\")\n",
    "cropper.process_dir(input_dir=directory) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize\n",
    "path_config=\"gpu.config.yml\"\n",
    "cfg = OmegaConf.load(path_config)\n",
    "analyzer = FaceAnalyzer(cfg.analyzer)\n",
    "\n",
    "#Warm up\n",
    "path_img_input=\"./test_error_1/frame_0.png\"\n",
    "response=None\n",
    "# warmup\n",
    "response = analyzer.run(\n",
    "        path_image=path_img_input,\n",
    "        batch_size=cfg.batch_size,\n",
    "        fix_img_size=cfg.fix_img_size,\n",
    "        return_img_data=False,\n",
    "        include_tensors=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [file for file in os.listdir(directory) if file.endswith(\".jpg\")]\n",
    "responses=[]\n",
    "for image_file in tqdm(image_files):\n",
    "        \n",
    "        # Get the full path of the image file\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "        \n",
    "        # Run the analyzer on the image\n",
    "        response = analyzer.run(\n",
    "            path_image=image_path,\n",
    "            batch_size=cfg.batch_size,\n",
    "            fix_img_size=cfg.fix_img_size,\n",
    "            return_img_data=cfg.return_img_data,\n",
    "            include_tensors=cfg.include_tensors,\n",
    "        )\n",
    "        responses.append(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
